
# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import altair as alt

st.set_page_config(page_title="æ¯æ—¥è‚¡ç¥¨ç¯©é¸å™¨ Â· GDrive ç‰ˆ", layout="wide")

# ----------------------------
# Utils
# ----------------------------
def gdrive_file_url(file_id: str) -> str:
    """è½‰æ› Google Drive FILE_ID ç‚ºå¯è®€å–çš„ç›´é€£ URL"""
    return f"https://drive.google.com/uc?export=download&id={file_id}"

@st.cache_data(ttl=1800, show_spinner="è®€å–è³‡æ–™ä¸­â€¦")
def load_data_from_gdrive(file_id: str) -> pd.DataFrame:
    url = gdrive_file_url(file_id)
    # å˜—è©¦å¤šç¨®å¸¸è¦‹ç·¨ç¢¼
    last_err = None
    for enc in ["cp950", "big5", "utf-8"]:
        try:
            df = pd.read_csv(url, encoding=enc, low_memory=False)
            break
        except Exception as e:
            last_err = e
            df = None
    if df is None:
        raise RuntimeError(f"è®€å–å¤±æ•—ï¼š{last_err}")

    # æ—¥æœŸè½‰æ›
    if "æ—¥æœŸ" not in df.columns:
        raise RuntimeError("ç¼ºå°‘ã€æ—¥æœŸã€æ¬„ä½")
    df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"].astype(str), format="%Y%m%d", errors="coerce")

    # ä»£ç¢¼/å•†å“æ¬„ä½
    if "ä»£ç¢¼" not in df.columns:
        raise RuntimeError("ç¼ºå°‘ã€ä»£ç¢¼ã€æ¬„ä½")
    df["ä»£ç¢¼"] = df["ä»£ç¢¼"].astype(str)
    if "å•†å“" not in df.columns:
        df["å•†å“"] = ""

    # å°‡å¯èƒ½å«é€—è™Ÿæˆ–å­—ä¸²çš„æ•¸å€¼æ¬„è½‰ç‚ºæ•¸å€¼
    def to_numeric(series):
        return pd.to_numeric(
            series.astype(str)
                  .str.replace(",", "", regex=False)
                  .str.replace("(", "-", regex=False)
                  .str.replace(")", "", regex=False),
            errors="coerce"
        )

    numeric_cols = [
        "é–‹ç›¤åƒ¹","æœ€é«˜åƒ¹","æœ€ä½åƒ¹","æ”¶ç›¤åƒ¹","æ¼²è·Œå¹…","æŒ¯å¹…","æˆäº¤é‡","å…§ç›¤é‡","å¤–ç›¤é‡","é–‹ç›¤é‡",
        "ç•¶æ—¥æ²–éŠ·å¼µæ•¸","52Håƒ¹","å‡åƒ¹","å‡åƒ¹[0+1]","å‡åƒ¹[1+2]","å‡åƒ¹[1+2+3]","å‡åƒ¹[0+1+2]",
        "èåˆ¸é¤˜é¡å¼µæ•¸","èåˆ¸å¢æ¸›å¼µæ•¸","æˆäº¤é‡‘é¡","é€±è½‰ç‡"
    ]
    for c in numeric_cols:
        if c in df.columns:
            df[c] = to_numeric(df[c])

    # æ’åº
    df = df.sort_values(["ä»£ç¢¼","æ—¥æœŸ"]).reset_index(drop=True)
    return df

def calc_abnormal_volume(df: pd.DataFrame, lookback: int = 5) -> pd.DataFrame:
    """è¨ˆç®—æ¯æª”çš„æ­·å²å‡é‡ï¼ˆæ’é™¤ç•¶æ—¥ï¼Œç”¨ shift(1)ï¼‰ï¼Œæ–°å¢æ¬„ä½ 'å‡é‡N'ã€'é‡èƒ½å€æ•¸'ã€‚"""
    if "æˆäº¤é‡" not in df.columns:
        raise RuntimeError("ç¼ºå°‘ã€æˆäº¤é‡ã€æ¬„ä½")
    df = df.copy()
    df[f"å‡é‡{lookback}"] = (
        df.groupby("ä»£ç¢¼")["æˆäº¤é‡"]
          .transform(lambda s: s.shift(1).rolling(window=lookback, min_periods=max(1, lookback//2)).mean())
    )
    df["é‡èƒ½å€æ•¸"] = df["æˆäº¤é‡"] / df[f"å‡é‡{lookback}"]
    return df

def section_title(title: str, help_text: str = ""):
    cols = st.columns([1, 0.06])
    with cols[0]:
        st.subheader(title)
    with cols[1]:
        if help_text:
            st.caption(help_text)

# ----------------------------
# Sidebar Â· Settings
# ----------------------------
st.sidebar.header("ğŸ“¦ è³‡æ–™ä¾†æºï¼ˆGoogle Driveï¼‰")
default_file_id = st.sidebar.text_input(
    "Google Drive FILE_ID",
    value="",
    help=(
        "ä¸Šå‚³ XQ.csv åˆ° Google Drive â†’ å–å¾—åˆ†äº«é€£çµï¼Œå½¢å¦‚ "
        "'https://drive.google.com/file/d/FILE_ID/view?usp=sharing'ï¼ŒæŠŠ FILE_ID è²¼åˆ°é€™è£¡ã€‚"
    )
)

if not default_file_id:
    st.info("è«‹åœ¨å·¦å´è¼¸å…¥ Google Drive çš„ FILE_ID å¾Œé–‹å§‹ã€‚")
    st.stop()

df = load_data_from_gdrive(default_file_id)

# å…ˆè¨ˆç®—ä¸€æ¬¡é‡èƒ½ç•°å¸¸ï¼ˆé è¨­ 5 æ—¥ï¼‰
df = calc_abnormal_volume(df, lookback=5)

st.sidebar.header("âš™ï¸ ç¯©é¸æ¢ä»¶")
# æ—¥æœŸé¸æ“‡ï¼ˆè½‰ Python dateï¼Œé¿å… numpy.datetime64 å‹åˆ¥å•é¡Œï¼‰
py_dates = df["æ—¥æœŸ"].dropna().sort_values().dt.date.unique()
default_date_py = py_dates[-1] if len(py_dates) else None
sel_date = st.sidebar.date_input("é¸æ“‡æ—¥æœŸ", value=default_date_py)
if isinstance(sel_date, (list, tuple)):
    sel_date = sel_date[0] if len(sel_date) else default_date_py

top_n = st.sidebar.slider("Top Nï¼ˆèåˆ¸å¢æ¸› / é‡èƒ½ç•°å¸¸ï¼‰", 5, 50, 10, 5)
limit_up_threshold = st.sidebar.number_input("æ¼²åœé–€æª»ï¼ˆ%ï¼‰", 0.0, 20.0, 9.9, 0.1)
vol_lookback = st.sidebar.selectbox("é‡èƒ½å‡é‡è¦–çª—", options=[5, 10, 20], index=0)
vol_multiple = st.sidebar.number_input("é‡èƒ½å€æ•¸é–€æª»ï¼ˆâ‰¥ï¼‰", 1.0, 20.0, 2.0, 0.5)

# ä¾é¸æ“‡é‡ç®—é‡èƒ½è¦–çª—
df = calc_abnormal_volume(df, lookback=int(vol_lookback))

# å–ç•¶æ—¥è³‡æ–™
mask_day = df["æ—¥æœŸ"].dt.date == sel_date
day = df.loc[mask_day].copy()

# ----------------------------
# 1) æ¼²åœå€‹è‚¡
# ----------------------------
section_title("1ï¼‰æ¼²åœå€‹è‚¡", "æ¢ä»¶ï¼šæ¼²è·Œå¹… â‰¥ é–€æª»")
if "æ¼²è·Œå¹…" not in day.columns:
    st.warning("æ‰¾ä¸åˆ°ã€æ¼²è·Œå¹…ã€æ¬„ä½ï¼Œç„¡æ³•è¨ˆç®—æ¼²åœ")
else:
    g_limit = day.loc[day["æ¼²è·Œå¹…"] >= limit_up_threshold].copy()
    show_cols = ["ä»£ç¢¼", "å•†å“", "æ”¶ç›¤åƒ¹", "æ¼²è·Œå¹…", "æˆäº¤é‡", "é€±è½‰ç‡"]
    table = g_limit[[c for c in show_cols if c in g_limit.columns]].sort_values(
        ["æ¼²è·Œå¹…","æˆäº¤é‡"], ascending=[False, False]
    )
    st.dataframe(table, use_container_width=True)

# ----------------------------
# 2) èåˆ¸å¢æ¸›æœ€å¤šå€‹è‚¡
# ----------------------------
section_title("2ï¼‰èåˆ¸å¢æ¸›æœ€å¤šå€‹è‚¡", "ä¾ã€èåˆ¸å¢æ¸›å¼µæ•¸ã€æ’åºï¼Œå– Top N")
if "èåˆ¸å¢æ¸›å¼µæ•¸" not in day.columns:
    st.warning("æ‰¾ä¸åˆ°ã€èåˆ¸å¢æ¸›å¼µæ•¸ã€æ¬„ä½ï¼Œç„¡æ³•ç”¢ç”Ÿæ’è¡Œæ¦œ")
else:
    rq_cols = ["ä»£ç¢¼", "å•†å“", "æ”¶ç›¤åƒ¹", "èåˆ¸å¢æ¸›å¼µæ•¸", "èåˆ¸é¤˜é¡å¼µæ•¸", "æˆäº¤é‡"]
    g_rq = (
        day.dropna(subset=["èåˆ¸å¢æ¸›å¼µæ•¸"])
           .sort_values("èåˆ¸å¢æ¸›å¼µæ•¸", ascending=False)
           .head(top_n)
    )
    st.dataframe(g_rq[[c for c in rq_cols if c in g_rq.columns]], use_container_width=True)

# ----------------------------
# 3) æˆäº¤é‡ç•°å¸¸å€‹è‚¡
# ----------------------------
section_title("3ï¼‰æˆäº¤é‡ç•°å¸¸å€‹è‚¡", "æ¢ä»¶ï¼šé‡èƒ½å€æ•¸ â‰¥ é–€æª»ï¼ˆä»Šæ—¥é‡ Ã· æ­·å²å‡é‡ï¼‰")
if not set(["æˆäº¤é‡", "é‡èƒ½å€æ•¸"]).issubset(day.columns):
    st.warning("ç¼ºå°‘ã€æˆäº¤é‡ã€æˆ–ã€é‡èƒ½å€æ•¸ã€æ¬„ä½")
else:
    vol_cols = ["ä»£ç¢¼", "å•†å“", "æˆäº¤é‡", f"å‡é‡{vol_lookback}", "é‡èƒ½å€æ•¸", "æ”¶ç›¤åƒ¹", "æ¼²è·Œå¹…"]
    g_vol = (
        day[(day["é‡èƒ½å€æ•¸"] >= float(vol_multiple)) & day[f"å‡é‡{vol_lookback}"].notna()]
        .copy()
        .sort_values("é‡èƒ½å€æ•¸", ascending=False)
        .head(top_n)
    )
    st.dataframe(g_vol[[c for c in vol_cols if c in g_vol.columns]], use_container_width=True)

# ----------------------------
# å€‹è‚¡èµ°å‹¢ï¼ˆäº’å‹•ï¼‰
# ----------------------------
section_title("å€‹è‚¡èµ°å‹¢ï¼ˆäº’å‹•ï¼‰", "å¾ä¸Šé¢çš„è¡¨æ ¼æŒ‘è‚¡ç¥¨æˆ–ç›´æ¥è¼¸å…¥ä»£ç¢¼")
codes_today = sorted(day["ä»£ç¢¼"].dropna().unique().tolist())
col_a, col_b = st.columns([1,1])
with col_a:
    sel_code = st.text_input("è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼", value=(codes_today[0] if codes_today else ""))

if sel_code:
    hist = df[df["ä»£ç¢¼"] == sel_code].copy()
    if hist.empty:
        st.info("æŸ¥ç„¡æ­¤ä»£ç¢¼çš„æ­·å²è³‡æ–™")
    else:
        st.markdown(f"**{sel_code} Â· {hist['å•†å“'].iloc[-1] if 'å•†å“' in hist.columns else ''}**")

        price_cols = [c for c in ["æ”¶ç›¤åƒ¹","é–‹ç›¤åƒ¹","æœ€é«˜åƒ¹","æœ€ä½åƒ¹"] if c in hist.columns]
        vol_cols = [c for c in ["æˆäº¤é‡", f"å‡é‡{vol_lookback}"] if c in hist.columns]

        base = alt.Chart(hist).encode(x="æ—¥æœŸ:T")

        if price_cols:
            chart_price = base.mark_line().transform_fold(
                price_cols, as_=["æŒ‡æ¨™","æ•¸å€¼"]
            ).encode(
                y=alt.Y("æ•¸å€¼:Q", title="åƒ¹æ ¼"),
                color="æŒ‡æ¨™:N"
            ).properties(height=260)
            st.altair_chart(chart_price, use_container_width=True)

        if vol_cols:
            chart_vol = base.transform_fold(
                vol_cols, as_=["é‡ç¨®","æ•¸å€¼"]
            ).mark_bar().encode(
                y=alt.Y("æ•¸å€¼:Q", title="æˆäº¤é‡ / å‡é‡"),
                color="é‡ç¨®:N"
            ).properties(height=180)
            st.altair_chart(chart_vol, use_container_width=True)

st.caption("è³‡æ–™ä¾†æºï¼šGoogle Drive XQ.csvï¼ˆå…¬é–‹å…±äº«é€£çµï¼‰ã€‚å»ºè­°æ¯æ—¥æ›´æ–°å¾Œé‡æ–°æ•´ç†é é¢ã€‚")
